{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12214369-f4ec-4a27-b3a1-60e8ed7af1a7",
   "metadata": {},
   "source": [
    "<h1>Problem Definition & Objectives</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ac8f8-bad5-4cd9-9616-a7a24b97413d",
   "metadata": {},
   "source": [
    "<h2>Objectives</h2>\n",
    "<ul>\n",
    "    <li>Build a trading algorithm using the optimal combination of Indicators </li>\n",
    "    <li>Backtest the strategy on historical stock data and compare its performance with the S&P 500</li>\n",
    "</ul>\n",
    "<h2>Key Goals</h2>\n",
    "<ul>\n",
    "    <li>Develop a trading startegy that balances return and risk.</li>\n",
    "    <li>Ensure the startegy is scalable, modular, and adheres to industry standards.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84451cd-6f6d-49d4-a3e5-91bf0e61ade7",
   "metadata": {},
   "source": [
    "<h2>Optimal Indicator Combination</h2>\n",
    "\n",
    "Feature Engineering to get the importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b06854-409f-464f-b354-a8687a78ef72",
   "metadata": {},
   "source": [
    "<h3>Data Ingestion for Optimal Indicator</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98187fb3-221b-4259-b6d2-cd4bb729669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical data using Yahoo Finance.\n",
    "    \n",
    "    Parameters:\n",
    "        ticker (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "        start_date (str): The start date for the data in 'YYYY-MM-DD' format.\n",
    "        end_date (str): The end date for the data in 'YYYY-MM-DD' format.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The historical data.\n",
    "    \"\"\"\n",
    "    return yf.download(ticker, start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb118a67-a01e-471d-8746-49590475c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_data('NVDA', '2010-01-01', '2024-09-09')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bdd4b7-8cce-4bcb-b24e-5552f88887f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87641532-32ac-4a15-9cd1-bf661deafeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8513b-1a1e-4d8b-b8ab-8ab3c39236ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e95e0d-2501-4336-8937-e8ff63be3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max())\n",
    "missing_dates = date_range.difference(df.index)\n",
    "print(f\"Missing dates: {missing_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7440b863-0b12-4f79-a160-509bb877d576",
   "metadata": {},
   "source": [
    "<h2>Reindex and Forward Fill</h2>\n",
    "<ul>\n",
    "    <li>Propogate the last known price across non-trading days (weekends and holidays)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404a3c8-b9dd-49d1-b505-770e9602734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f9509-2c16-44cf-8bf6-8fe590ffd4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the DataFrame to include all dates\n",
    "df_full = df.reindex(date_range)\n",
    "\n",
    "# Fill missing values with forward fill (propagating the last known value)\n",
    "df_full.fillna(method='ffill', inplace=True)\n",
    "\n",
    "missing_values = df_full.isnull().sum()\n",
    "print(f\"Missing values after forward fill: \\n{missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37de9d-7e53-40c7-ae4f-204876ff7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f0460-5f7f-475e-aec5-ba163c825621",
   "metadata": {},
   "source": [
    "<h3>Define Indicators using TA-Lib for Optimal Indicator Combination</h3>\n",
    "<ul>\n",
    "    <li>Trend</li>\n",
    "    <li>Momentum</li>\n",
    "    <li>Volume</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67172234-466d-4fcd-af50-897f6307c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "#Define functions to add from TA-Lib Indicators\n",
    "def add_indicators(df):\n",
    "    high_prices = df['High']\n",
    "    low_prices = df['Low']\n",
    "    close_prices = df['Close']\n",
    "    volume = df['Volume']\n",
    "\n",
    "    \n",
    "    \n",
    "    #Trend Indicators\n",
    "    #1 SSL High and Low\n",
    "    df['SMA_High'] = talib.SMA(df['High'], timeperiod=21)\n",
    "    df['SMA_Low'] = talib.SMA(df['Low'], timeperiod=21)\n",
    "    print(\"indicator added.\")\n",
    "\n",
    "    #2 MACD\n",
    "    df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "\n",
    "    #3 TRIX\n",
    "    df['TRIX'] = talib.TRIX(close_prices, timeperiod=15)\n",
    "    df['TRIX_Signal'] = talib.SMA(df['TRIX'], timeperiod=9)\n",
    "\n",
    "\n",
    "    #4 AROON\n",
    "    df['AROON_DOWN'], df['AROON_UP'] = talib.AROON(high_prices, low_prices, timeperiod=14)\n",
    "\n",
    "\n",
    "    #Momentum Indicators\n",
    "    #1 Stochastic\n",
    "\n",
    "    df['STOCH_K'], df['STOCH_D'] = talib.STOCH(high_prices, low_prices, close_prices,\n",
    "                                          fastk_period=5,\n",
    "                                          slowk_period=3,\n",
    "                                          slowk_matype=0,\n",
    "                                          slowd_period=3,\n",
    "                                          slowd_matype=0)\n",
    "\n",
    "    df['STOCH_FK'], df['STOCH_SK'] = talib.STOCHF(high_prices, low_prices, close_prices,\n",
    "                                            fastk_period=5,\n",
    "                                            fastd_period=3,\n",
    "                                            fastd_matype=0)\n",
    "\n",
    "\n",
    "    #2 Williams Percent Range\n",
    "    df['WILLIAMS_R'] = talib.WILLR(high_prices, low_prices, close_prices, timeperiod=14)\n",
    "\n",
    "\n",
    "    #3 Money Flow Index\n",
    "    df['MFI'] = talib.MFI(high_prices, low_prices, close_prices, volume, timeperiod=14)\n",
    "\n",
    "\n",
    "    #4 Ultimate Oschillator\n",
    "    df['ULTIMATE_OSCILLATOR'] = talib.ULTOSC(high_prices, low_prices, close_prices, timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "\n",
    "\n",
    "    #Volume Indicators\n",
    "    #1 On Balance Volume\n",
    "    df['OBV'] = talib.OBV(close_prices, volume)\n",
    "\n",
    "\n",
    "    #2 Chaikin Money Flow\n",
    "    df['CMF'] = talib.ADOSC(high_prices, low_prices, close_prices, volume, fastperiod=3, slowperiod=10)\n",
    "\n",
    "\n",
    "    #3 PVI Positive Volume Index and NVI Negative Volume Index\n",
    "    df['PVI'] = pd.Series(index=close_prices.index, data=1000.0)\n",
    "    df['NVI'] = pd.Series(index=close_prices.index, data=1000.0)\n",
    "\n",
    "    for i in range(1, len(close_prices)):\n",
    "        if df['Volume'].iloc[i] > df['Volume'].iloc[i - 1]: #PVI: Update if today's volume is higher than yesterday\n",
    "            df.loc[i, 'PVI'] = df['PVI'].iloc[i - 1] * (1 + (df['Close'].iloc[i] - df['Close'].iloc[i - 1]) / df['Close'].iloc[i - 1])\n",
    "        else:\n",
    "            df.loc[i, 'PVI'] = df['PVI'].iloc[i - 1] #No Change if Volume didn't increase\n",
    "\n",
    "        if df['Volume'].iloc[i] < df['Volume'].iloc[i - 1]: # NVI: Update if today's volume is lower than yesterday\n",
    "            df.loc[i, 'NVI'] = df['NVI'].iloc[i - 1] * (1 + (df['Close'].iloc[i] - df['Close'].iloc[i - 1]) / df['Close'].iloc[i - 1])\n",
    "        else:\n",
    "            df.loc[i, 'NVI'] = df['NVI'].iloc[i - 1] # No Change if volume didn't decrease\n",
    "    print(\"returning dataframe\")\n",
    "\n",
    "    # Set a long-term moving average for PVI and NVI\n",
    "    df['PVI_MA'] = df['PVI'].rolling(window=255).mean()\n",
    "    df['NVI_MA'] = df['NVI'].rolling(window=255).mean()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720883bf-b141-4f1c-ab01-cb549f431e71",
   "metadata": {},
   "source": [
    "<h2>High Importance Features</h2>\n",
    "<ul>\n",
    "    <li>PVI_MA</li>\n",
    "    <li>OBV</li>\n",
    "    <li>SMA_High</li>\n",
    "    <li>STOCH_FK</li>\n",
    "    <li>NVI_MA</li>\n",
    "    <li>SMA_Low</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64a036-e357-4175-bf85-c81a4f196ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "#Define functions to add from TA-Lib Indicators\n",
    "def add_high_important_indicators(df):\n",
    "    high_prices = df['High']\n",
    "    low_prices = df['Low']\n",
    "    close_prices = df['Close']\n",
    "    volume = df['Volume']\n",
    "\n",
    "    \n",
    "    \n",
    "    #Trend Indicators\n",
    "    #1 SSL High and Low\n",
    "    df['SMA_High'] = talib.SMA(df['High'], timeperiod=21)\n",
    "    df['SMA_Low'] = talib.SMA(df['Low'], timeperiod=21)\n",
    "    print(\"indicator added.\")\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #Momentum Indicators\n",
    "    #1 Stochastic\n",
    "\n",
    "    df['STOCH_FK'], df['STOCH_SK'] = talib.STOCHF(high_prices, low_prices, close_prices,\n",
    "                                            fastk_period=5,\n",
    "                                            fastd_period=3,\n",
    "                                            fastd_matype=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Volume Indicators\n",
    "    #1 On Balance Volume\n",
    "    df['OBV'] = talib.OBV(close_prices, volume)\n",
    "\n",
    "\n",
    "    #3 PVI Positive Volume Index and NVI Negative Volume Index\n",
    "    df['PVI'] = pd.Series(index=close_prices.index, data=1000.0)\n",
    "    df['NVI'] = pd.Series(index=close_prices.index, data=1000.0)\n",
    "\n",
    "    for i in range(1, len(close_prices)):\n",
    "        if df['Volume'].iloc[i] > df['Volume'].iloc[i - 1]: #PVI: Update if today's volume is higher than yesterday\n",
    "            df.loc[i, 'PVI'] = df['PVI'].iloc[i - 1] * (1 + (df['Close'].iloc[i] - df['Close'].iloc[i - 1]) / df['Close'].iloc[i - 1])\n",
    "        else:\n",
    "            df.loc[i, 'PVI'] = df['PVI'].iloc[i - 1] #No Change if Volume didn't increase\n",
    "\n",
    "        if df['Volume'].iloc[i] < df['Volume'].iloc[i - 1]: # NVI: Update if today's volume is lower than yesterday\n",
    "            df.loc[i, 'NVI'] = df['NVI'].iloc[i - 1] * (1 + (df['Close'].iloc[i] - df['Close'].iloc[i - 1]) / df['Close'].iloc[i - 1])\n",
    "        else:\n",
    "            df.loc[i, 'NVI'] = df['NVI'].iloc[i - 1] # No Change if volume didn't decrease\n",
    "    print(\"returning dataframe\")\n",
    "\n",
    "    # Set a long-term moving average for PVI and NVI\n",
    "    df['PVI_MA'] = df['PVI'].rolling(window=255).mean()\n",
    "    df['NVI_MA'] = df['NVI'].rolling(window=255).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494103b-7a8e-4c89-b207-55c7034b4a7c",
   "metadata": {},
   "source": [
    "<h2>Preprocess Data (Handle Missing Values)</h2>\n",
    "<p>Just dropping the na values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c806d-a3f7-479d-8a61-0eb662146484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_full.copy(deep=True)\n",
    "df_copy.dropna()\n",
    "df_indicators = add_indicators(df_copy)\n",
    "df_indicators.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e7f40-9563-480e-9f0a-b9fdf71e99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951eb548-0fbf-45b4-ba1d-1415ff7570f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_indicators.dropna()\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a5ac38-7ad5-4c1c-8efe-7924748fccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca3143-5bb0-408e-a996-7bf3419c1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc4e58-0bbd-47cb-91c5-b76255e4a89b",
   "metadata": {},
   "source": [
    "<h2>Define Buy and Sell Signals for each indicator</h2>\n",
    "<p>Unoptimized Threshholds</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa150896-465a-4326-ac52-cbcdcf30b013",
   "metadata": {},
   "source": [
    "<h3>Trend Indicators</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55f9e3-7c3e-4be9-9f90-0c762bc78645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cleaned_copy = df_cleaned.copy(deep=True)\n",
    "\n",
    "# SSL Buy/Sell Signals\n",
    "# df_cleaned['SSL_Buy'] = ((df_cleaned['Close'] > df_cleaned['SMA_High']) & (df_cleaned['Close'].shift(1) <= df_cleaned['SMA_High'].shift(1))).astype(int)\n",
    "# df_cleaned['SSL_Sell'] = ((df_cleaned['Close'] < df_cleaned['SMA_Low']) & (df_cleaned['Close'].shift(1) >= df_cleaned['SMA_Low'].shift(1))).astype(int)\n",
    "df_cleaned_copy.loc[:, 'SSL_Buy'] = (df_cleaned_copy['Close'] > df_cleaned_copy['SMA_High']).astype(int)\n",
    "df_cleaned_copy.loc[:, 'SSL_Sell'] = (df_cleaned_copy['Close'] < df_cleaned_copy['SMA_Low']).astype(int)\n",
    "                          \n",
    "# MACD Buy/Sell Signals\n",
    "# # MACD Crosses above signal line\n",
    "# df_cleaned['MACD_Buy'] = ((df_cleaned['MACD'] > df_cleaned['MACD_signal']) & (df_cleaned['MACD'].shift(1) <= df_cleaned['MACD_signal'].shift(1))).astype(int)\n",
    "# # MACD Crosses below the signal line\n",
    "# df_cleaned['MACD_Sell'] = ((df_cleaned['MACD'] < df_cleaned['MACD_signal']) & (df_cleaned['MACD'].shift(1) >= df_cleaned['MACD_signal'].shift(1))).astype(int)\n",
    "# MACD Crosses above signal line\n",
    "df_cleaned_copy.loc[:, 'MACD_Buy'] = (df_cleaned_copy['MACD'] > df_cleaned_copy['MACD_signal']).astype(int)\n",
    "# MACD Crosses below the signal line\n",
    "df_cleaned_copy.loc[:, 'MACD_Sell'] = (df_cleaned_copy['MACD'] < df_cleaned_copy['MACD_signal']).astype(int)\n",
    "\n",
    "# TRIX Buy/Sell Signals\n",
    "# df_cleaned['TRIX_Buy'] = ((df_cleaned['TRIX'] > df_cleaned['TRIX_Signal']) & (df_cleaned['TRIX'].shift(1) <= df_cleaned['TRIX_Signal'].shift(1))).astype(int)\n",
    "# df_cleaned['TRIX_Sell'] = ((df_cleaned['TRIX'] < df_cleaned['TRIX_Signal']) & (df_cleaned['TRIX'].shift(1) >= df_cleaned['TRIX_Signal'].shift(1))).astype(int)\n",
    "# TRIX Buy/Sell Signals\n",
    "df_cleaned_copy.loc[:, 'TRIX_Buy'] = (df_cleaned_copy['TRIX'] > df_cleaned_copy['TRIX_Signal']).astype(int)\n",
    "df_cleaned_copy.loc[:, 'TRIX_Sell'] = (df_cleaned_copy['TRIX'] < df_cleaned_copy['TRIX_Signal']).astype(int)\n",
    "\n",
    "\n",
    "# ARRON If just using the Aroon then use the shift(1) to detect the crossing\n",
    "df_cleaned_copy.loc[:, 'AROON_Buy'] = (df_cleaned_copy['AROON_UP'] > df_cleaned_copy['AROON_DOWN']).astype(int)\n",
    "df_cleaned_copy.loc[:, 'AROON_Sell'] = (df_cleaned_copy['AROON_DOWN'] > df_cleaned_copy['AROON_UP']).astype(int)\n",
    "# df_cleaned['AROON_Buy'] = ((df_cleaned['AROON_UP'] > df_cleaned['AROON_DOWN']) & (df_cleaned['AROON_UP'].shift(1) <= df_cleaned['AROON_DOWN'].shift(1))).astype(int)\n",
    "# df_cleaned['AROON_Sell'] = ((df_cleaned['AROON_DOWN'] > df_cleaned['AROON_UP']) & (df_cleaned['AROON_DOWN'].shift(1) <= df_cleaned['AROON_UP'].shift(1))).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb64fd2-cf37-4776-b76d-b4551b508941",
   "metadata": {},
   "source": [
    "<h3>Momentum Indicators</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa2717-8212-420d-bfdb-e6fb6b7d7b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stochastic: Create Buy and Sell Signals based on %K and %D crossovers\n",
    "# # Fast %K above Fast %D if looking for the cross then use the shift(1)\n",
    "# df_cleaned['Stoch_Fast_Buy'] = ((df_cleaned['STOCH_FK'] > df_cleaned['STOCH_SK']) & (df_cleaned['STOCH_FK'].shift(1) <= df_cleaned['STOCH_SK'].shift(1))).astype(int)\n",
    "# # Fast %K crosses below Fast %D \n",
    "# df_cleaned['Stoch_Fast_Sell'] = ((df_cleaned['STOCH_FK'] < df_cleaned['STOCH_SK']) & (df_cleaned['STOCH_FK'].shift(1) >= df_cleaned['STOCH_SK'].shift(1))).astype(int)\n",
    "# # Slow %K crosses above slow %D\n",
    "# df_cleaned['Stoch_Slow_Buy'] = ((df_cleaned['STOCH_K'] > df_cleaned['STOCH_D']) & (df_cleaned['STOCH_K'].shift(1) <= df_cleaned['STOCH_D'].shift(1))).astype(int)\n",
    "# # Slow %K crosses below slow %D\n",
    "# df_cleaned['Stoch_Slow_Sell'] = ((df_cleaned['STOCH_K'] < df_cleaned['STOCH_D']) & (df_cleaned['STOCH_K'].shift(1) >= df_cleaned['STOCH_D'].shift(1))).astype(int)\n",
    "\n",
    "# Fast %K above Fast %D if looking for the cross then use the shift(1)\n",
    "df_cleaned_copy.loc[:,'Stoch_Fast_Buy'] = (df_cleaned['STOCH_FK'] > df_cleaned['STOCH_SK']).astype(int)\n",
    "# Fast %K crosses below Fast %D \n",
    "df_cleaned_copy.loc[:,'Stoch_Fast_Sell'] = (df_cleaned['STOCH_FK'] < df_cleaned['STOCH_SK']).astype(int)\n",
    "# Slow %K crosses above slow %D\n",
    "df_cleaned_copy.loc[:,'Stoch_Slow_Buy'] = (df_cleaned['STOCH_K'] > df_cleaned['STOCH_D']).astype(int)\n",
    "# Slow %K crosses below slow %D\n",
    "df_cleaned_copy.loc[:,'Stoch_Slow_Sell'] = (df_cleaned['STOCH_K'] < df_cleaned['STOCH_D']).astype(int)\n",
    "\n",
    "# Williams %R\n",
    "# # %R crosses above -80 \n",
    "# df_cleaned['Williams_Buy'] = ((df_cleaned['WILLIAMS_R'] > -80) & (df_cleaned['WILLIAMS_R'].shift(1) <= -80)).astype(int)\n",
    "# # %R crosses below -20 \n",
    "# df_cleaned['Williams_Sell'] = ((df_cleaned['WILLIAMS_R'] < -20) & (df_cleaned['WILLIAMS_R'].shift(1) >= -20)).astype(int)\n",
    "# %R crosses above -80 \n",
    "df_cleaned_copy.loc[:,'Williams_Buy'] = (df_cleaned['WILLIAMS_R'] > -80).astype(int)\n",
    "# %R crosses below -20 \n",
    "df_cleaned_copy.loc[:,'Williams_Sell'] = (df_cleaned['WILLIAMS_R'] < -20).astype(int)\n",
    "\n",
    "# MFI\n",
    "# # MFI crosses above 20\n",
    "# df_cleaned['MFI_Buy'] = ((df_cleaned['MFI'] > 20) & (df_cleaned['MFI'].shift(1) <= 20)).astype(int)\n",
    "# # MFI crosses below 80\n",
    "# df_cleaned['MFI_Sell'] = ((df_cleaned['MFI'] < 80) & (df_cleaned['MFI'].shift(1) >= 80)).astype(int)\n",
    "# MFI crosses above 20\n",
    "df_cleaned_copy.loc[:,'MFI_Buy'] = (df_cleaned['MFI'] > 20).astype(int)\n",
    "# MFI crosses below 80\n",
    "df_cleaned_copy.loc[:,'MFI_Sell'] = (df_cleaned['MFI'] < 80).astype(int)\n",
    "\n",
    "# Ultimate Oscillator\n",
    "# # UO crosses above 30 \n",
    "# df_cleaned['UOSC_Buy'] = ((df_cleaned['ULTIMATE_OSCILLATOR'] > 30) & (df_cleaned['ULTIMATE_OSCILLATOR'].shift(1) <= 30)).astype(int)\n",
    "# df_cleaned['UOSC_Sell'] = ((df_cleaned['ULTIMATE_OSCILLATOR'] < 70) & (df_cleaned['ULTIMATE_OSCILLATOR'].shift(1) >= 70)).astype(int)\n",
    "                          # UO crosses above 30 \n",
    "df_cleaned_copy.loc[:,'UOSC_Buy'] = (df_cleaned['ULTIMATE_OSCILLATOR'] > 30).astype(int)\n",
    "df_cleaned_copy.loc[:,'UOSC_Sell'] = (df_cleaned['ULTIMATE_OSCILLATOR'] < 70).astype(int)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491c9b8-062d-4af8-8c83-0020ad7be1df",
   "metadata": {},
   "source": [
    "<h3>Volume Indicators</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d5a25-80de-4cc5-a956-068b2023ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBV \n",
    "# OBV is increaseing \n",
    "df_cleaned_copy.loc[:, 'OBV_Buy'] = (df_cleaned['OBV'] > df_cleaned['OBV'].shift(1)).astype(int)\n",
    "# OBV is decreasing\n",
    "df_cleaned_copy.loc[:, 'OBV_Sell'] = (df_cleaned['OBV'] < df_cleaned['OBV'].shift(1)).astype(int)\n",
    "\n",
    "# CMF\n",
    "# CMF crosses above 0\n",
    "df_cleaned_copy.loc[:, 'CMF_Buy'] = ((df_cleaned['CMF'] > 0) & (df_cleaned['CMF'].shift(1) <= 0)).astype(int)\n",
    "# CMF crosses below 0 \n",
    "df_cleaned_copy.loc[:, 'CMF_Sell'] = ((df_cleaned['CMF'] < 0) & (df_cleaned['CMF'].shift(1) >= 0)).astype(int)\n",
    "\n",
    "# PVI\n",
    "# PVI crosses above its moving average\n",
    "df_cleaned_copy.loc[:, 'PVI_Buy'] = ((df_cleaned['PVI'] > df_cleaned['PVI_MA']) & (df_cleaned['PVI'].shift(1) <= df_cleaned['PVI_MA'])).astype(int)\n",
    "# PVI crosses below its moving average\n",
    "df_cleaned_copy.loc[:, 'PVI_Sell'] = ((df_cleaned['PVI'] < df_cleaned['PVI_MA']) & (df_cleaned['PVI'].shift(1) >= df_cleaned['PVI_MA'])).astype(int)\n",
    "\n",
    "# NVI\n",
    "# NVI crosses above its moving average\n",
    "df_cleaned_copy.loc[:, 'NVI_Buy'] = ((df_cleaned['NVI'] > df_cleaned['NVI_MA']) & (df_cleaned['NVI'].shift(1) <= df_cleaned['NVI_MA'])).astype(int)\n",
    "# PVI crosses below its moving average\n",
    "df_cleaned_copy.loc[:, 'NVI_Sell'] = ((df_cleaned['NVI'] < df_cleaned['NVI_MA']) & (df_cleaned['NVI'].shift(1) >= df_cleaned['NVI_MA'])).astype(int)\n",
    "\n",
    "\n",
    "df_cleaned_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fad85b-c95b-4d95-992d-70a59355c0c0",
   "metadata": {},
   "source": [
    "<h2>Combine signals for buy and sell</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55035d7-b348-4e63-a505-08848a6af1fe",
   "metadata": {},
   "source": [
    "<h3>Tool to iterate through all the possible combinations and output the buy and sell signal code</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c36ecc-1dd9-466e-ae7d-99c3ceca2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Trend Indicators\n",
    "trend_indicators = ['SSL', 'MACD', 'TRIX', 'AROON']\n",
    "\n",
    "# Momentum Indicators\n",
    "momentum_indicators = ['Stoch_Fast', 'Stoch_Slow', 'Williams', 'MFI', 'UOSC']\n",
    "\n",
    "# Volume Indicators\n",
    "volume_indicators = ['OBV', 'CMF', 'PVI', 'NVI']\n",
    "\n",
    "# Generate all combinations\n",
    "combinations = list(itertools.product(trend_indicators, momentum_indicators, volume_indicators))\n",
    "\n",
    "# Generate buy and sell signal code for each combination\n",
    "for combo in combinations:\n",
    "    trend, momentum, volume = combo\n",
    "    \n",
    "    print(f\"# Combination: {trend.upper()} (Trend), {momentum.upper()} (Momentum), {volume.upper()} (Volume)\")\n",
    "    print(f\"df_cleaned_copy['buy_signal'] = (\")\n",
    "    print(f\"    (df_cleaned_copy['{momentum}_Buy'] == 1) & \")\n",
    "    print(f\"    (df_cleaned_copy['{trend}_Buy'] == 1) & \")\n",
    "    print(f\"    (df_cleaned_copy['{volume}_Buy'] == 1)\")\n",
    "    print(f\").astype(int)\")\n",
    "    \n",
    "    print(f\"df_cleaned_copy['sell_signal'] = (\")\n",
    "    print(f\"    (df_cleaned_copy['{momentum}_Sell'] == 1) & \")\n",
    "    print(f\"    (df_cleaned_copy['{trend}_Sell'] == 1) & \")\n",
    "    print(f\"    (df_cleaned_copy['{volume}_Sell'] == 1)\")\n",
    "    print(f\").astype(int)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142e605-3f6e-4c50-bec3-a5f9c0ac8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0251d-4281-4622-ae9a-bf5821d54478",
   "metadata": {},
   "source": [
    "<h2>Define Buy and Sell Signals for each combination of indicators</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e410b-ee5c-4a0d-9de6-9454081b31b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combination: SSL (Trend), STOCH_FAST (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), STOCH_FAST (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), STOCH_FAST (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), STOCH_FAST (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), STOCH_SLOW (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), STOCH_SLOW (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), STOCH_SLOW (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), STOCH_SLOW (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), WILLIAMS (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), WILLIAMS (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), WILLIAMS (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), WILLIAMS (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), MFI (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), MFI (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), MFI (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), MFI (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), UOSC (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), UOSC (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), UOSC (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: SSL (Trend), UOSC (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['SSL_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), STOCH_FAST (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), STOCH_FAST (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), STOCH_FAST (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), STOCH_FAST (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), STOCH_SLOW (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), STOCH_SLOW (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), STOCH_SLOW (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), STOCH_SLOW (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), WILLIAMS (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), WILLIAMS (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), WILLIAMS (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), WILLIAMS (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), MFI (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), MFI (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), MFI (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), MFI (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), UOSC (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), UOSC (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), UOSC (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: MACD (Trend), UOSC (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['MACD_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), STOCH_FAST (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), STOCH_FAST (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), STOCH_FAST (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), STOCH_FAST (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), STOCH_SLOW (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), STOCH_SLOW (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), STOCH_SLOW (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), STOCH_SLOW (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), WILLIAMS (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), WILLIAMS (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), WILLIAMS (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), WILLIAMS (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), MFI (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), MFI (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), MFI (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), MFI (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), UOSC (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), UOSC (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), UOSC (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: TRIX (Trend), UOSC (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['TRIX_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), STOCH_FAST (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), STOCH_FAST (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), STOCH_FAST (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), STOCH_FAST (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Fast_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), STOCH_SLOW (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), STOCH_SLOW (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), STOCH_SLOW (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), STOCH_SLOW (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Stoch_Slow_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), WILLIAMS (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), WILLIAMS (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), WILLIAMS (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), WILLIAMS (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['Williams_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), MFI (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), MFI (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), MFI (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), MFI (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['MFI_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), UOSC (Momentum), OBV (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['OBV_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), UOSC (Momentum), CMF (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['CMF_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), UOSC (Momentum), PVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['PVI_Sell'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Combination: AROON (Trend), UOSC (Momentum), NVI (Volume)\n",
    "df_cleaned_copy['buy_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Buy'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Buy'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Buy'] == 1)\n",
    ").astype(int)\n",
    "df_cleaned_copy['sell_signal'] = (\n",
    "    (df_cleaned_copy['UOSC_Sell'] == 1) & \n",
    "    (df_cleaned_copy['AROON_Sell'] == 1) & \n",
    "    (df_cleaned_copy['NVI_Sell'] == 1)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1301d12-e693-48da-9759-2bf8211d7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target as 1 (buy), -1 (sell), and 0 (hold)\n",
    "df_cleaned_copy['target'] = 0\n",
    "df_cleaned_copy['target'] = df_cleaned_copy['target'].mask(df_cleaned_copy['buy_signal'] == 1, 1)\n",
    "df_cleaned_copy['target'] = df_cleaned_copy['target'].mask(df_cleaned_copy['sell_signal'] == 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94185068-a9f3-4bce-b314-c708f5943644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_copy.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2472e78-c644-42de-a667-c4ef333c463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where buy_signal or sell_signal has a value of 1\n",
    "buy_sell_signals = df_cleaned_copy[(df_cleaned_copy['target'] == 1) | (df_cleaned_copy['target'] == -1)]\n",
    "\n",
    "# Display the filtered results\n",
    "print(buy_sell_signals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4aa14-95e9-4782-8621-8a9281ce3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in buy_sell_signals.iterrows():\n",
    "    cols_with_ones = row[row == 1].index.tolist()\n",
    "    print(f\"Row {index}: Columns with value 1: {cols_with_ones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01abe32-3571-4711-9175-d8d21c3acb6c",
   "metadata": {},
   "source": [
    "<p> No Trades. This is probably a result from the signal at the exact cross over. To procede with getting trades I think I need to remove the cross over signal. Removing shift from momentum. </p>\n",
    "\n",
    "<h4>Hypothesis 1: Removing Stochastics previous day shift. </h4>\n",
    "<h5>Results in 2 rows over the course 14 years</h5>\n",
    "<h4>Hypothesis 2: Removing Trend previous day shifts & Momentum shifts. Leaving the Volume shifts.</h4>\n",
    "<h5>18 buy or sell signals over the course of 14 years.</h5>\n",
    "<ul>\n",
    "    <li>Good: If you are aiming for a long-term, trend-following strategy, fewer signals might indicate that your strategy is filtering out noise and capturing only significant moves.</li>\n",
    "    <li>Bad: If you are using a momentum or shorter-term trading strategy, 18 signals over 14 years might indicate that the strategy is too conservative, missing potential opportunities.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff917e7e-3ef5-45c7-b05a-c993d766ccbb",
   "metadata": {},
   "source": [
    "<h2>Machine Learning Pipeline with Scikit-Learn</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4786f5-778e-41cb-a916-7342e93e6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Select Features for the Model\n",
    "X = df_cleaned[['SMA_High', 'SMA_Low', 'MACD', 'MACD_signal', 'MACD_hist', 'TRIX', 'TRIX_Signal',\n",
    "       'AROON_DOWN', 'AROON_UP', 'STOCH_K', 'STOCH_D', 'STOCH_FK', 'STOCH_SK',\n",
    "       'WILLIAMS_R', 'MFI', 'ULTIMATE_OSCILLATOR', 'OBV', 'CMF', 'PVI', 'NVI',\n",
    "       'PVI_MA', 'NVI_MA']]\n",
    "y = df_cleaned['target']\n",
    "\n",
    "# Split the data set in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale the features\n",
    "    ('clf', RandomForestClassifier())  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "train_acc = pipeline.score(X_train, y_train)\n",
    "test_acc = pipeline.score(X_test, y_test)\n",
    "print(f\"Train Accuracy: {train_acc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6378e-e2ed-4b51-8d6d-57823b2fc13c",
   "metadata": {},
   "source": [
    "<h1>Round 2 after Feature Importance: Removed Less Important Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4298b88-8047-4842-9ae8-5c024556c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Select Features for the Model\n",
    "X = df_cleaned[['SMA_High', 'SMA_Low', 'MACD', 'MACD_signal', 'MACD_hist', 'STOCH_K', 'STOCH_D', 'STOCH_FK', 'STOCH_SK',\n",
    "       'WILLIAMS_R', 'MFI', 'ULTIMATE_OSCILLATOR', 'OBV', 'PVI', 'NVI', 'PVI_MA', 'NVI_MA']]\n",
    "y = df_cleaned['target']\n",
    "\n",
    "# Split the data set in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale the features\n",
    "    ('clf', RandomForestClassifier())  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "train_acc = pipeline.score(X_train, y_train)\n",
    "test_acc = pipeline.score(X_test, y_test)\n",
    "print(f\"Train Accuracy: {train_acc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac47272-8bf6-4a5b-8c0c-49d46d2a576d",
   "metadata": {},
   "source": [
    "<h1>Round 3 Focus on High Importance Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667cfb5b-b1cb-462e-9a37-bdf03105b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Select Features for the Model\n",
    "X = df_cleaned_copy[['SMA_High', 'SMA_Low', 'STOCH_FK', 'OBV','PVI_MA', 'NVI_MA']]\n",
    "y = df_cleaned_copy['target']\n",
    "\n",
    "# Split the data set in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale the features\n",
    "    ('clf', RandomForestClassifier())  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "train_acc = pipeline.score(X_train, y_train)\n",
    "test_acc = pipeline.score(X_test, y_test)\n",
    "print(f\"Train Accuracy: {train_acc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528e0e7-fb70-48fe-b8ef-d16236a19a73",
   "metadata": {},
   "source": [
    "<h1>Hyperparameter Tuning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c676c-5573-4c61-8326-d890e5ce9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200, 500],  # Number of trees\n",
    "    'clf__max_depth': [None, 10, 20, 30],  # Max depth of each tree\n",
    "    'clf__min_samples_split': [2, 5, 10],  # Minimum samples for split\n",
    "    'clf__min_samples_leaf': [1, 2, 4]  # Minimum samples in a leaf node\n",
    "}\n",
    "\n",
    "# Perform Grid Search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Params: {best_params}\")\n",
    "print(f\"Best Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1178f-12ef-45f0-a8ed-9fd99eafa98e",
   "metadata": {},
   "source": [
    "<h5>Round 2 Results:</h5>\n",
    "<ul>\n",
    "    <li> Best Params: {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}</li>\n",
    "    <li> Best Score: 0.9962629721965822</li>\n",
    "</ul>\n",
    "\n",
    "<h5>Round 3 Results:</h5>\n",
    "<ul>\n",
    "    <li>Best Params: {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}</li>\n",
    "    <li>Best Score: 1.0</li>\n",
    "</ul>\n",
    "\n",
    " \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba3cfb-24bb-4279-b242-47e0ba56cb30",
   "metadata": {},
   "source": [
    "<h1>Feature Importance</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6093f3bd-cf46-40a9-9e21-139777dba43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Extract the trained classifier from the pipeline\n",
    "clf = grid_search.best_estimator_.named_steps['clf']\n",
    "\n",
    "# Get feature importance from the trained model\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Get the feature names from your input data\n",
    "feature_names = X_train.columns  # Ensure you use the correct DataFrame or array here\n",
    "\n",
    "# Create a DataFrame for better readability and sorting\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance for better visualization\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for Buy/Sell Signals\")\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to show the most important feature at the top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902cd8fc-d80c-4928-9d5b-41e2135fa63d",
   "metadata": {},
   "source": [
    "<h1>Backtest High Important Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569b140f-10a2-45f5-8330-56cbe279dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Backtest:\n",
    "    def __init__(self, strategy, ticker, start_date, end_date, cash=50000, commission=0.001):\n",
    "        \"\"\"\n",
    "        Initializes the backtest environment.\n",
    "        \n",
    "        Parameters:\n",
    "            strategy (bt.Strategy): The trading strategy class.\n",
    "            ticker (str): Stock ticker symbol for fetching data (e.g., 'AAPL').\n",
    "            start_date (str): Start date of historical data (format: 'YYYY-MM-DD').\n",
    "            end_date (str): End date of historical data (format: 'YYYY-MM-DD').\n",
    "            cash (float): Initial cash for the backtest. Default is 50,000.\n",
    "            commission (float): Commission per trade. Default is 0.1%.\n",
    "        \"\"\"\n",
    "        self.strategy = strategy\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.cash = cash\n",
    "        self.commission = commission\n",
    "\n",
    "    def run_backtest(self):\n",
    "        \"\"\"\n",
    "        Runs the backtest on the provided strategy and data.\n",
    "        \n",
    "        Returns:\n",
    "            cerebro (bt.Cerebro): The Backtrader engine instance.\n",
    "        \"\"\"\n",
    "        # Initialize Backtrader engine (Cerebro)\n",
    "        cerebro = bt.Cerebro()\n",
    "\n",
    "        # Add Strategy\n",
    "        cerebro.addstrategy(self.strategy)\n",
    "\n",
    "        # Fetch data using yfinance\n",
    "        data = self.fetch_data()\n",
    "\n",
    "        # Convert the data into a Backtrader feed and add it to cerebro\n",
    "        data_feed = bt.feeds.PandasData(dataname=data)\n",
    "\n",
    "        cerebro.adddata(data_feed)\n",
    "\n",
    "        # Set Initial cash and comission\n",
    "        cerebro.broker.setcash(self.cash)\n",
    "        cerebro.broker.setcommission(commission=self.commission)\n",
    "\n",
    "        # Run the backtest\n",
    "        results = cerebro.run()\n",
    "\n",
    "        print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "        final_value = cerebro.broker.getvalue()\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        initial_value = self.cash\n",
    "        years = (data.index[-1] - data.index[0]).days / 365.25\n",
    "        portfolio_returns = pd.Series([x.broker.getvalue() for x in results])\n",
    "\n",
    "        cagr = self.calculate_cagr(initial_value, final_value, years)\n",
    "        sharpe_ratio = self.calculate_sharpe_ratio(portfolio_returns)\n",
    "        std_dev = portfolio_returns.pct_change().std()\n",
    "        max_drawdown = self.calculate_max_drawdown(portfolio_returns)\n",
    "\n",
    "        # Print the calculated metrics\n",
    "        print(f\"CAGR: {cagr:.2f}\")\n",
    "        print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "        print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "        print(f\"Max Drawdown: {max_drawdown:.2f}\")\n",
    "\n",
    "        #return the cerebro engine for further analysis or plotting\n",
    "        return {\n",
    "           'final_value': final_value,\n",
    "            'CAGR': cagr,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Standard Deviation': std_dev,\n",
    "            'Max Drawdown': max_drawdown\n",
    "        }\n",
    "\n",
    "  \n",
    "    def calculate_cagr(self, initial_value, final_value, years):\n",
    "        \"\"\"\n",
    "        Calculate the Compound Annual Growth Rate (CAGR)\n",
    "        \"\"\"\n",
    "        return (final_value / initial_value) ** (1 / years) - 1\n",
    "\n",
    "    def calculate_sharpe_ratio(self, returns, risk_free_rate=0):\n",
    "        \"\"\"\n",
    "        Calculate Sharpe Ratio (Assumes daily returns)\n",
    "        \"\"\"\n",
    "        mean_return = returns.pct_change().mean()\n",
    "        std_dev = returns.pct_change().std()\n",
    "        return (mean_return - risk_free_rate) / std_dev\n",
    "\n",
    "    def calculate_max_drawdown(self, portfolio_values):\n",
    "        \"\"\"\n",
    "        Calculate the maximum drawdown\n",
    "        \"\"\"\n",
    "        rolling_max = portfolio_values.cummax()\n",
    "        drawdown = (portfolio_values - rolling_max) / rolling_max\n",
    "        return drawdown.min()\n",
    "\n",
    "    def fetch_data(self):\n",
    "        \"\"\"\n",
    "        Fetch historical data from Yahoo Finance using yfinance.\n",
    "\n",
    "        Returns: pd.DataFrame: Historical stock data for the ticker.\n",
    "        \"\"\"\n",
    "        data = yf.download(self.ticker, start=self.start_date, end=self.end_date)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def plot_results(self, cerebro):\n",
    "        \"\"\"\n",
    "        Plots the backtest results.\n",
    "        Parameters: cerebro (bt.Cerebro): The Backtrader engine instance.\n",
    "        \"\"\"\n",
    "        cerebro._exactbars = 0\n",
    "        \n",
    "        cerebro.plot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ebe05b-a697-4866-b9f6-ff0cef75c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskManager:\n",
    "    def __init__(self, broker, atr, risk_percent=0.01, atr_multiplier=2.0):\n",
    "        \"\"\"\n",
    "        Initializes the Risk Manager with ATR and risk settings.\n",
    "\n",
    "        Parameters:\n",
    "        - broker: Reference to the Backtrader broker to get current portfolio value.\n",
    "        - atr: The ATR indicator.\n",
    "        - risk_percent: The percentage of capital to risk per trade (default is 1%).\n",
    "        - atr_multiplier: The multiple of ATR for setting stop loss and take profit (default is 2x ATR).\n",
    "        \"\"\"\n",
    "        self.broker = broker\n",
    "        self.atr = atr\n",
    "        self.risk_percent = risk_percent\n",
    "        self.atr_multiplier = atr_multiplier\n",
    "\n",
    "    def calculate_position_size(self, current_price, trade_type='buy'):\n",
    "        \"\"\"\n",
    "        Calculates the position size based on ATR and risk percentage.\n",
    "\n",
    "        Parameters:\n",
    "        - current_price: The current price of the asset.\n",
    "        - trade_type: 'buy' for long trades, 'sell' for short trades.\n",
    "\n",
    "        Returns:\n",
    "        - position_size: The calculated position size based on risk.\n",
    "        - stop_loss_price: The calculated stop loss price based on ATR.\n",
    "        - take_profit_price: The calculated take profit price based on ATR.\n",
    "        \"\"\"\n",
    "        capital_at_risk = self.broker.getvalue() * self.risk_percent\n",
    "\n",
    "        if trade_type == 'buy':\n",
    "            # Long trade (buy): stop loss below the current price\n",
    "            stop_loss_price = current_price - (self.atr_multiplier * self.atr[0])\n",
    "            take_profit_price = current_price + (self.atr_multiplier * self.atr[0]) * 3 # 1:3 risk-reward\n",
    "        else:\n",
    "            # Short trade (sell): stop loss above the current price\n",
    "            stop_loss_price = current_price + (self.atr_multiplier * self.atr[0])\n",
    "            take_profit_price = current_price - (self.atr_multiplier * self.atr[0] * 3)  # 1:3 risk-reward\n",
    "            \n",
    "        position_size = capital_at_risk / abs(current_price - stop_loss_price)\n",
    "        return position_size, stop_loss_price, take_profit_price\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62d32bb3-ba1d-42d2-894d-00f529bb2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighImportanceFeatureStrategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('sma_high_period', 20),  # Example period for SMA_High\n",
    "        ('sma_low_period', 20),   # Example period for SMA_Low\n",
    "        ('stoch_fk_period', 14),  # Example period for STOCH_FK\n",
    "        ('pvi_ma_period', 20),    # Example period for PVI_MA\n",
    "        ('nvi_ma_period', 20)     # Example period for NVI_MA\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # Define the indicators for the selected features\n",
    "        self.sma_high = bt.indicators.SimpleMovingAverage(self.data.high, period=self.params.sma_high_period)\n",
    "        self.sma_low = bt.indicators.SimpleMovingAverage(self.data.low, period=self.params.sma_low_period)\n",
    "        self.stoch_fk = bt.indicators.StochasticFast(self.data, period=self.params.stoch_fk_period)\n",
    "        self.obv = OBV(self.data)\n",
    "        self.pvi_ma = bt.indicators.SimpleMovingAverage(self.data.volume, period=self.params.pvi_ma_period)\n",
    "        self.nvi_ma = bt.indicators.SimpleMovingAverage(self.data.volume, period=self.params.nvi_ma_period)\n",
    "\n",
    "    def next(self):\n",
    "        # Example buy condition using the selected indicators\n",
    "        if self.data.close[0] > self.sma_high[0] and self.obv[0] > self.obv[-1]:\n",
    "            self.buy()\n",
    "            print(f\"BUY ORDER CREATED: Close={self.data.close[0]}, SMA_High={self.sma_high[0]}, STOCH_K={self.stoch_fk.percK[0]}, OBV={self.obv[0]}\")\n",
    "        \n",
    "        # Example sell condition using the selected indicators\n",
    "        if self.data.close[0] < self.sma_low[0] and self.obv[0] < self.obv[-1]:\n",
    "            self.sell()\n",
    "            print(f\"SELL ORDER CREATED: Close={self.data.close[0]}, SMA_Low={self.sma_low[0]}, STOCH_K={self.stoch_fk.percK[0]}, OBV={self.obv[0]}\")\n",
    "\n",
    "    def stop(self):\n",
    "        # Print final portfolio value from the strategy's perspective\n",
    "        print(f\"Strategy Stop: Final Portfolio Value: {self.broker.getvalue()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fb31619-1c73-4675-9466-8812d4136ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PVI_NVI_Strategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('pvi_ma_period', 255), # Default period for PVI_MA\n",
    "        ('nvi_ma_period', 255), # Default period for NVI_MA\n",
    "        ('atr_period', 14), # ATR period for volatility\n",
    "        ('risk_percent', 0.01), # Risk percentage of capital per trade\n",
    "        ('atr_multiplier', 2.0), # 2x ATR for stop loss and take profit\n",
    "        ('trail_stop_atr_multiplier', 1.5), # ATR multiplier for trailing stop loss\n",
    "        ('risk_reward_ratio', 3.0), # 1:3 risk-reward ratio\n",
    "        ('max_total_risk', 0.02),  # Maximum total risk across all positions (2%)\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # Define the Indicators for the selected features\n",
    "        self.pvi = PVI(self.data)\n",
    "        self.nvi = NVI(self.data)\n",
    "        self.pvi_ma = PVI_MA(self.data, self.params.pvi_ma_period)\n",
    "        self.nvi_ma = NVI_MA(self.data, self.params.nvi_ma_period)\n",
    "        self.obv = OBV(self.data)\n",
    "        self.atr = bt.indicators.AverageTrueRange(self.data, period=self.params.atr_period)\n",
    "\n",
    "        # Risk Adjusted Transaction\n",
    "        # Initialize RiskManager with the current broker, ATR, and risk settings\n",
    "        self.risk_manager = RiskManager(self.broker, self.atr, risk_percent=self.params.risk_percent, atr_multiplier=self.params.atr_multiplier)\n",
    "        \n",
    "        self.buy_price = None\n",
    "        self.take_profit_price = None\n",
    "        self.stop_loss_price = None\n",
    "\n",
    "    def next(self):\n",
    "        # Calculate the current risk exposure across all positions\n",
    "        self.total_risk_exposure = self.calculate_total_risk_exposure()\n",
    "\n",
    "        # Check is a new trade can be placed without exceeding the max total risk\n",
    "        if self.total_risk_exposure < self.params.max_total_risk:\n",
    "            # Buy if PVI crosses above its moving average\n",
    "            if (self.pvi[0] > self.pvi_ma[0] and self.obv[0] > self.obv[-1]) or (self.nvi[0] > self.nvi_ma[0] and self.obv[0] > self.obv[-1]):\n",
    "                # Caluculate position size, stop loss, and take profit using the RiskManager\n",
    "                position_size, stop_loss_price, take_profit_price = self.risk_manager.calculate_position_size(self.data.close[0], trade_type='buy')\n",
    "\n",
    "                # Execute buy order\n",
    "                self.buy(size=position_size)\n",
    "                self.buy_price = self.data.close[0]\n",
    "                self.take_profit_price = take_profit_price\n",
    "                self.stop_loss_price = stop_loss_price\n",
    "\n",
    "                print(f\"Buy Order: Buy Price={self.buy_price}, Take Profit={self.take_profit_price}, Stop Loss={self.stop_loss_price}, Position Size={position_size}\")\n",
    "\n",
    "\n",
    "            # Sell if PVI crosses below its moving average\n",
    "            elif (self.pvi[0] < self.pvi_ma[0] and self.obv[0] > self.obv[-1]) or (self.nvi[0] < self.nvi_ma[0] and self.obv[0] > self.obv[-1]):\n",
    "                # Calculate position size, stop loss, and take profit for short trade\n",
    "                position_size, stop_loss_price, take_profit_price = self.risk_manager.calculate_position_size(self.data.close[0], trade_type='sell')\n",
    "\n",
    "                # Execute sell order\n",
    "                self.sell(size=position_size)\n",
    "                self.buy_price = self.data.close[0]\n",
    "                self.stop_loss_price = stop_loss_price\n",
    "                self.take_profit_price = take_profit_price\n",
    "\n",
    "                print(f\"Sell Order: Sell Price={self.buy_price}, Stop Loss={self.stop_loss_price}, Take Profit={self.take_profit_price}, Position Size={position_size}\")\n",
    "\n",
    "            \n",
    "        # If a position is open, apply trailing stop loss and check for take profit\n",
    "        if self.position:\n",
    "            new_stop_loss = self.calculate_trailing_stop()\n",
    "            if self.data.close[0] <= self.stop_loss_price:\n",
    "                self.close()\n",
    "                print(f\"Stop Loss Hit at {self.data.close[0]}, Sell Order Executed\")\n",
    "            elif self.data.close[0] >= self.take_profit_price:\n",
    "                self.close()\n",
    "                print(f\"Take Profit Reached at {self.data.close[0]}, Sell Order Executed\")\n",
    "\n",
    "    def calculate_total_risk_exposure(self):\n",
    "        \"\"\"\n",
    "        Calculate the total risk exposure across all open positions.\n",
    "        This method sums the risk for each open position based on its stop loss distance.\n",
    "        \"\"\"\n",
    "        total_risk = 0\n",
    "        for position in self.broker.positions:\n",
    "            current_price = self.data.close[0]\n",
    "\n",
    "            # Calculate the total risk exposure across all positions\n",
    "            stop_loss_distance = abs(current_price - self.stop_loss_price)\n",
    "            position_risk = stop_loss_distance * position.size\n",
    "            total_risk += position_risk / self.broker.getvalue()\n",
    "\n",
    "        return total_risk\n",
    "\n",
    "    def calculate_trailing_stop(self):\n",
    "        # Dynamically update trailing stop loss\n",
    "            new_stop_loss = self.data.close[0] - (self.params.trail_stop_atr_multiplier * self.atr[0])\n",
    "            if new_stop_loss > self.stop_loss_price:\n",
    "                self.stop_loss_price = new_stop_loss\n",
    "            return new_stop_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c489a-7893-4648-a7c8-b7e9a40f8c60",
   "metadata": {},
   "source": [
    "<h1>PVI and NVI MAs Indicator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c84ec55a-734c-45c9-ae2a-dac08251b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PVI_MA(bt.Indicator):\n",
    "    lines = ('pvi_ma',)\n",
    "    \n",
    "    def __init__(self, period=255):\n",
    "        self.pvi = PVI(self.data)  # Use the PVI indicator\n",
    "        self.lines.pvi_ma = bt.indicators.SimpleMovingAverage(self.pvi, period=period)\n",
    "\n",
    "class NVI_MA(bt.Indicator):\n",
    "    lines = ('nvi_ma',)\n",
    "    \n",
    "    def __init__(self, period=255):\n",
    "        self.nvi = NVI(self.data)  # Use the NVI indicator\n",
    "        self.lines.nvi_ma = bt.indicators.SimpleMovingAverage(self.nvi, period=period)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c1390-aa1a-4380-a402-087e1bb3bf30",
   "metadata": {},
   "source": [
    "<h1>PVI Indicator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "610b8bae-7f2e-447f-a164-2c04819d623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PVI(bt.Indicator):\n",
    "    lines = ('pvi',)\n",
    "    \n",
    "    params = (('initial_value', 1000),)  # Default initial value\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.addminperiod(1)\n",
    "        self.pvi_value = self.params.initial_value  # Start at 1000\n",
    "    \n",
    "    def next(self):\n",
    "        if len(self) == 1: # First Data Point\n",
    "            self.lines.pvi[0] = self.params.initial_value # Initialize PVI at 1000 for the first bar\n",
    "        else:\n",
    "            if self.data.volume[0] > self.data.volume[-1]:\n",
    "                # Calculate the change in price and update PVI\n",
    "                self.lines.pvi[0] = self.lines.pvi[-1] * (1 + (self.data.close[0] - self.data.close[-1]) / self.data.close[-1])\n",
    "            else:\n",
    "                # No change in PVI if today's volume is less than or equal to yesterday's\n",
    "                self.lines.pvi[0] = self.lines.pvi[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6b958-f3ff-4ded-88b9-c02080f54a59",
   "metadata": {},
   "source": [
    "<h1>NVI Indicator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1efe692-5db8-494f-a343-e6bb6a13541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NVI(bt.Indicator):\n",
    "    lines = ('nvi',)\n",
    "    \n",
    "    params = (('initial_value', 1000),)  # Default initial value\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.addminperiod(1)\n",
    "        self.nvi_value = self.params.initial_value  # Start at 1000\n",
    "    \n",
    "    def next(self):\n",
    "        if len(self) == 1: # First Data Point\n",
    "            self.lines.nvi[0] = self.params.initial_value # Initialize NVI at 1000\n",
    "        else:\n",
    "            if self.data.volume[0] < self.data.volume[-1]:\n",
    "                # Calculate the change in price and update NVI\n",
    "                self.lines.nvi[0] = self.lines.nvi[-1] * (1 + (self.data.close[0] - self.data.close[-1]) / self.data.close[-1])\n",
    "            else:\n",
    "                # No change in NVI if today's volume is greater than or equal to yesterday's\n",
    "                self.lines.nvi[0] = self.lines.nvi[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03055602-b481-4a0c-8fd3-d3ef106d5b09",
   "metadata": {},
   "source": [
    "<h1>OBV Indicator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f9f564c-5e55-4756-848a-b9466dafc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define OBV as a custom indicator\n",
    "class OBV(bt.Indicator):\n",
    "    # Define the line that will be computed (in this case, 'obv')\n",
    "    lines = ('obv',)\n",
    "    \n",
    "    # Set the parameters (if you need to add any later, like smoothing)\n",
    "    params = dict()\n",
    "\n",
    "    # Initialize the indicator\n",
    "    def __init__(self):\n",
    "        # Set a minimum period to ensure we have data to compute OBV\n",
    "        self.addminperiod(1)\n",
    "    \n",
    "    # Define how OBV will be calculated for each bar (time step)\n",
    "    def next(self):\n",
    "        if len(self) == 1:\n",
    "            # Initialize OBV at 0 for the first bar\n",
    "            self.lines.obv[0] = 0\n",
    "        else:\n",
    "            # If today's close is greater than yesterday's close, add today's volume\n",
    "            if self.data.close[0] > self.data.close[-1]:\n",
    "                self.lines.obv[0] = self.lines.obv[-1] + self.data.volume[0]\n",
    "            # If today's close is less than yesterday's close, subtract today's volume\n",
    "            elif self.data.close[0] < self.data.close[-1]:\n",
    "                self.lines.obv[0] = self.lines.obv[-1] - self.data.volume[0]\n",
    "            # If today's close is equal to yesterday's close, OBV remains unchanged\n",
    "            else:\n",
    "                self.lines.obv[0] = self.lines.obv[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f8b67b1-38c3-4b50-97dd-6455c160a901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy Order: Buy Price=0.4244999885559082, Take Profit=0.4938110855686769, Stop Loss=0.40139628955165196, Position Size=21641.556181453383\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m backtest \u001b[38;5;241m=\u001b[39m Backtest(\n\u001b[1;32m      4\u001b[0m     strategy \u001b[38;5;241m=\u001b[39m PVI_NVI_Strategy,\n\u001b[1;32m      5\u001b[0m     ticker \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNVDA\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     commission\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbacktest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m, in \u001b[0;36mBacktest.run_backtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m cerebro\u001b[38;5;241m.\u001b[39mbroker\u001b[38;5;241m.\u001b[39msetcommission(commission\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommission)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Run the backtest\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcerebro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal Portfolio Value: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m cerebro\u001b[38;5;241m.\u001b[39mbroker\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m     55\u001b[0m final_value \u001b[38;5;241m=\u001b[39m cerebro\u001b[38;5;241m.\u001b[39mbroker\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/envs/Algo_Indicator_0/lib/python3.9/site-packages/backtrader/cerebro.py:1132\u001b[0m, in \u001b[0;36mCerebro.run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dooptimize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\u001b[38;5;241m.\u001b[39mmaxcpus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# If no optimmization is wished ... or 1 core is to be used\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# let's skip process \"spawning\"\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iterstrat \u001b[38;5;129;01min\u001b[39;00m iterstrats:\n\u001b[0;32m-> 1132\u001b[0m         runstrat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunstrategies\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterstrat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunstrats\u001b[38;5;241m.\u001b[39mappend(runstrat)\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dooptimize:\n",
      "File \u001b[0;32m~/anaconda3/envs/Algo_Indicator_0/lib/python3.9/site-packages/backtrader/cerebro.py:1298\u001b[0m, in \u001b[0;36mCerebro.runstrategies\u001b[0;34m(self, iterstrat, predata)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runonce_old(runstrats)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1298\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runonce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunstrats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\u001b[38;5;241m.\u001b[39moldsync:\n",
      "File \u001b[0;32m~/anaconda3/envs/Algo_Indicator_0/lib/python3.9/site-packages/backtrader/cerebro.py:1700\u001b[0m, in \u001b[0;36mCerebro._runonce\u001b[0;34m(self, runstrats)\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timers(runstrats, dt0, cheat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m strat \u001b[38;5;129;01min\u001b[39;00m runstrats:\n\u001b[0;32m-> 1700\u001b[0m     \u001b[43mstrat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oncepost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_stop:  \u001b[38;5;66;03m# stop if requested\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Algo_Indicator_0/lib/python3.9/site-packages/backtrader/strategy.py:309\u001b[0m, in \u001b[0;36mStrategy._oncepost\u001b[0;34m(self, dt)\u001b[0m\n\u001b[1;32m    307\u001b[0m minperstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getminperstatus()\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m minperstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minperstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnextstart()  \u001b[38;5;66;03m# only called for the 1st value\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 32\u001b[0m, in \u001b[0;36mPVI_NVI_Strategy.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate the current risk exposure across all positions\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_risk_exposure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_total_risk_exposure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Check is a new trade can be placed without exceeding the max total risk\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_risk_exposure \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmax_total_risk:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# Buy if PVI crosses above its moving average\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 83\u001b[0m, in \u001b[0;36mPVI_NVI_Strategy.calculate_total_risk_exposure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m     current_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclose[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     82\u001b[0m     stop_loss_distance \u001b[38;5;241m=\u001b[39m current_price \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_loss_price\n\u001b[0;32m---> 83\u001b[0m     position_risk \u001b[38;5;241m=\u001b[39m \u001b[43mstop_loss_distance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\n\u001b[1;32m     84\u001b[0m     total_risk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_risk \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbroker\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_risk\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'method'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "backtest = Backtest(\n",
    "    strategy = PVI_NVI_Strategy,\n",
    "    ticker = 'NVDA',\n",
    "    start_date = '2010-01-01',\n",
    "    end_date = '2024-09-18',\n",
    "    cash=50000,\n",
    "    commission=0.001\n",
    ")\n",
    "\n",
    "results = backtest.run_backtest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "481bff45-dbf5-4841-976c-6c90816e38ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_value': 211665.7271009429, 'CAGR': 0.10312513353530628, 'Sharpe Ratio': nan, 'Standard Deviation': nan, 'Max Drawdown': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae25ec-49b6-4103-8217-28a17df6bce6",
   "metadata": {},
   "source": [
    "<h1>Optimal RSI Buy and RSI sell threshholds</h1>\n",
    "<p>Maximizing the Sharpe Ratio or Cumulative Returns</p>\n",
    "<h4>Hypothesis:</h4>\n",
    "<p>Instead of using fixed levels ( RSI 30 for buy and RSI 70 for sell), aim to optimize these threshholds to improve the strategy's performance over historical data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293b478-2681-40b0-8305-332cb5c6c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "display(Javascript(\"IPython.notebook.kernel.restart()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941512a8-ca95-4eff-9c40-925f6c339631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back Testing \n",
    "# Sharpe Ratio\n",
    "# Maximum Drawdown\n",
    "# Cumulative Return\n",
    "\n",
    "import backtrader as bt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "class Backtest:\n",
    "    \"\"\"\n",
    "    A class to handle backtesting using Backtrader.\n",
    "    \n",
    "    Attributes:\n",
    "        strategy (bt.Strategy): The strategy class to be tested.\n",
    "        data (pd.DataFrame): The historical data to be used for backtesting.\n",
    "        cash (float): The initial capital.\n",
    "        commission (float): The commission per trade.\n",
    "\n",
    "    Methods:\n",
    "        run_backtest(): Sets up the backtest and returns the cerebro engine for further analysis or plotting.\n",
    "        plot_results(): Plots the results of the backtest using BackTrader's built in plot functionality.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, strategy, data, cash=10000, commission=0.001):\n",
    "        \"\"\"\n",
    "        Initialize the Backtest class with strategy, data, cash, and commission.\n",
    "        \n",
    "        Parameters:\n",
    "            strategy (bt.Strategy): A Backtrader strategy class.\n",
    "            data (pd.DataFrame): Historical market data for backtesting.\n",
    "            cash (float): Initial cash for backtesting. Default is 10,000.\n",
    "            commission (float): Commission per trade. Default is 0.1%.\n",
    "        \"\"\"\n",
    "        self.strategy = strategy\n",
    "        self.data = data\n",
    "        self.cash = cash\n",
    "        self.commission = commission\n",
    "\n",
    "    def run_backtest(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Execute the backtest with the provided strategy and data.\n",
    "\n",
    "        Parameters: \n",
    "            **kwargs: Arguments to override the strategy parameters.\n",
    "        \n",
    "        Returns:\n",
    "            cerebro: The Backtrader engine instance with the run results.\n",
    "        \"\"\"\n",
    "        cerebro = bt.Cerebro()\n",
    "\n",
    "        # Add the strategy to Cerebro\n",
    "        cerebro.addstrategy(self.strategy)\n",
    "\n",
    "        # Convert the DataFrame to Backtrader Data Feed\n",
    "        data_feed = bt.feeds.PandasData(dataname=self.data)\n",
    "        cerebro.adddata(data_feed)\n",
    "\n",
    "        # Set initial cash\n",
    "        cerebro.broker.setcash(self.cash)\n",
    "\n",
    "        # Set commission\n",
    "        cerebro.broker.setcommission(commission=self.commission)\n",
    "\n",
    "        # Run the backtest\n",
    "        results = cerebro.run()\n",
    "\n",
    "        # Return the engine instance for further analysis or plotting\n",
    "        return cerebro, results\n",
    "\n",
    "    def plot_results(self, cerebro):\n",
    "        \"\"\"\n",
    "        Plot the results of the backtest.\n",
    "        \n",
    "        Parameters:\n",
    "            cerebro: The Backtrader engine instance with the run results.\n",
    "        \"\"\"\n",
    "        cerebro.plot(style='candlestick')\n",
    "\n",
    "class RSI_Strategy(bt.Strategy):\n",
    "    \"\"\"\n",
    "    A simple RSI-based trading strategy.\n",
    "    \n",
    "    Attributes:\n",
    "        rsi_period (int): The period for calculating RSI.\n",
    "        rsi_buy (int): The RSI threshold for buying.\n",
    "        rsi_sell (int): The RSI threshold for selling.\n",
    "\n",
    "    Methods:\n",
    "        next(): This method is called for every time step (data point).\n",
    "    \"\"\"\n",
    "    \n",
    "    params = (\n",
    "        ('rsi_period', 14),  # Default RSI period\n",
    "        ('rsi_buy', 30),     # Default RSI buy threshold\n",
    "        ('rsi_sell', 70),    # Default RSI sell threshold\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the strategy and indicators.\n",
    "        \"\"\"\n",
    "        self.rsi = bt.indicators.RelativeStrengthIndex(self.data.close, period=self.params.rsi_period)\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"\n",
    "        This method is called on every time step (new data point) to evaluate\n",
    "        the trading logic.\n",
    "        \"\"\"\n",
    "        # Check if there are no open positions\n",
    "        if not self.position:\n",
    "            # Buy condition: RSI below the buy threshold\n",
    "            if self.rsi < self.params.rsi_buy:\n",
    "                self.buy()\n",
    "        \n",
    "        # Check if there is an open position\n",
    "        else:\n",
    "            # Sell condition: RSI above the sell threshold\n",
    "            if self.rsi > self.params.rsi_sell:\n",
    "                self.sell()\n",
    "\n",
    "class SSL_RSI_Strategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('ssl_period', 10),  # Period for the moving averages used in SSL\n",
    "        ('rsi_period', 14),  # RSI period\n",
    "        ('rsi_buy', 30),     # RSI level to buy\n",
    "        ('rsi_sell', 70),    # RSI level to sell\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # SSL Semaphore Signal: Moving Average crossovers\n",
    "        self.sma_high = bt.indicators.SimpleMovingAverage(self.data.high, period=self.params.ssl_period)\n",
    "        self.sma_low = bt.indicators.SimpleMovingAverage(self.data.low, period=self.params.ssl_period)\n",
    "\n",
    "        # RSI Indicator\n",
    "        self.rsi = bt.indicators.RelativeStrengthIndex(self.data.close, period=self.params.rsi_period)\n",
    "\n",
    "    def next(self):\n",
    "        # Generate SSL-based buy and sell signals\n",
    "        if not self.position:  # No open positions\n",
    "            # Buy condition: price above SSL and RSI confirms oversold\n",
    "            if self.data.close > self.sma_high and self.rsi < self.params.rsi_buy:\n",
    "                self.buy()\n",
    "        \n",
    "        elif self.position:\n",
    "            # Sell condition: price below SSL and RSI confirms overbought\n",
    "            if self.data.close < self.sma_low and self.rsi > self.params.rsi_sell:\n",
    "                self.sell()\n",
    "\n",
    "class SSL_RSI_ATR_Strategy(bt.Strategy):\n",
    "    \"\"\"\n",
    "    A strategy using SSL Semaphore Signal and RSI, with ATR for dynamic risk management.\n",
    "    \"\"\"\n",
    "\n",
    "    params = (\n",
    "        ('ssl_period', 41),       \n",
    "        ('rsi_period', 13),       \n",
    "        ('rsi_buy', 41),          \n",
    "        ('rsi_sell', 74),         \n",
    "        ('atr_period', 14),       \n",
    "        ('atr_multiplier', 2.0),  \n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # SSL Semaphore Signal\n",
    "        self.sma_high = bt.indicators.SimpleMovingAverage(self.data.high, period=self.params.ssl_period)\n",
    "        self.sma_low = bt.indicators.SimpleMovingAverage(self.data.low, period=self.params.ssl_period)\n",
    "\n",
    "        # RSI Indicator\n",
    "        self.rsi = bt.indicators.RelativeStrengthIndex(self.data.close, period=self.params.rsi_period)\n",
    "\n",
    "        # ATR Indicator\n",
    "        self.atr = bt.indicators.AverageTrueRange(self.data, period=self.params.atr_period)\n",
    "\n",
    "        # Track buy price\n",
    "        self.buy_price = None\n",
    "\n",
    "    def next(self):\n",
    "        #DEBUGGING\n",
    "        # Debugging: Print the values of the indicators to check if they make sense\n",
    "        print(f\"Close: {self.data.close[0]}, SMA High: {self.sma_high[0]}, SMA Low: {self.sma_low[0]}, RSI: {self.rsi[0]}, ATR: {self.atr[0]}\")\n",
    "        \n",
    "        # If no position is open\n",
    "        if not self.position:\n",
    "            #RSI DEBUG\n",
    "            if self.rsi < self.params.rsi_buy:\n",
    "                print(f\"BUY RSI: {self.rsi}, Params: {self.params.rsi_buy}\")\n",
    "            elif self.rsi > self.params.rsi_sell:\n",
    "                print(f\"SELL RSI: {self.rsi}, Params: {self.params.rsi_sell}\")\n",
    "\n",
    "            #SSL DEBUG\n",
    "            if self.data.close > self.sma_high:\n",
    "                print(f\"BUY SSL\")\n",
    "            elif self.data.close < self.sma_low:\n",
    "                print(f\"SELL SSL\")\n",
    "                \n",
    "            # Buy if price is above SSL and RSI is below buy threshold\n",
    "            if self.data.close > self.sma_high and self.rsi < self.params.rsi_buy:\n",
    "                self.buy()\n",
    "                self.buy_price = self.data.close[0]  # Track buy price\n",
    "                print(f\"Buy Order Placed at {self.buy_price}\")\n",
    "        \n",
    "        # If a position is open, use the external ATR-based risk management\n",
    "        else:\n",
    "            manage_atr_risk(self, self.buy_price, self.atr[0], self.data.close[0], self.params.atr_multiplier)\n",
    "            print(f\"Managing Position: Current Price: {self.data.close[0]}, Buy Price: {self.buy_price}\")\n",
    "    \n",
    "\n",
    "def fetch_data(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical data using Yahoo Finance.\n",
    "    \n",
    "    Parameters:\n",
    "        ticker (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "        start_date (str): The start date for the data in 'YYYY-MM-DD' format.\n",
    "        end_date (str): The end date for the data in 'YYYY-MM-DD' format.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The historical data.\n",
    "    \"\"\"\n",
    "    return yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "def manage_atr_risk(strategy, buy_price, atr, current_price, atr_multiplier=2.0):\n",
    "    \"\"\"\n",
    "    Manage risk using ATR-based stop loss and take profit levels.\n",
    "    \n",
    "    Parameters:\n",
    "        strategy (bt.Strategy): The strategy instance (used for buying/selling).\n",
    "        buy_price (float): The price at which the position was bought.\n",
    "        atr (float): The current ATR value.\n",
    "        current_price (float): The current market price.\n",
    "        atr_multiplier (float): The multiplier for setting stop loss/take profit levels.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Calculate take profit and stop loss levels based on ATR\n",
    "    take_profit_price = buy_price + atr * atr_multiplier\n",
    "    stop_loss_price = buy_price - atr * atr_multiplier\n",
    "\n",
    "    # Take profit condition\n",
    "    if current_price >= take_profit_price:\n",
    "        strategy.sell()  # Execute a sell order\n",
    "        strategy.buy_price = None  # Reset buy price after selling\n",
    "\n",
    "    # Stop loss condition\n",
    "    elif current_price <= stop_loss_price:\n",
    "        strategy.sell()  # Execute a sell order\n",
    "        strategy.buy_price = None  # Reset buy price after selling\n",
    "\n",
    "\n",
    "def run_rsi_backtest(ticker, rsi_buy=30, rsi_sell=70, rsi_period=21):\n",
    "    \"\"\"\n",
    "    Run a backtest on the specified ticker with the given RSI thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "        ticker (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "        rsi_buy (int): The RSI level below which to buy.\n",
    "        rsi_sell (int): The RSI level above which to sell.\n",
    "    \n",
    "    Returns:\n",
    "        cerebro: The Backtrader engine instance with the run results.\n",
    "    \"\"\"\n",
    "    # Fetch historical data\n",
    "    data = fetch_data(ticker, '2010-01-01', '2024-09-09')\n",
    "\n",
    "    # Define the RSI strategy with the chosen buy and sell levels\n",
    "    strategy = RSI_Strategy\n",
    "    \n",
    "    # Create the backtest with the chosen strategy and data\n",
    "    backtest = Backtest(strategy, data)\n",
    "\n",
    "    # Run the backtest\n",
    "    cerebro, results = backtest.run_backtest(rsi_buy=rsi_buy, rsi_sell=rsi_sell, rsi_period=rsi_period)\n",
    "\n",
    "    # Get the initial and final portfolio values directly from Backtrader\n",
    "    initial_value = backtest.cash  # Initial value is the cash we started with\n",
    "    final_value = cerebro.broker.getvalue()  # Final portfolio value after the backtest\n",
    "\n",
    "    # Calculate cumulative return\n",
    "    cumulative_return = (final_value - initial_value) / initial_value * 100  # In percentage\n",
    "\n",
    "    # Calculate Sharpe Ratio (you can refine this calculation)\n",
    "    sharpe_ratio = (final_value - initial_value) / (data['Close'].std() * len(data) ** 0.5)  # Simple Sharpe Ratio\n",
    "\n",
    "    # Maximum Drawdown\n",
    "    # Extract portfolio values for maximum drawdown calculation\n",
    "    portfolio_values = [x.broker.getvalue() for x in results]\n",
    "\n",
    "    # Compute maximum drawdown\n",
    "    if portfolio_values:  # Ensure portfolio_values is not empty\n",
    "        max_drawdown = (1 - min(portfolio_values) / max(portfolio_values)) * 100  # In percentage\n",
    "    else:\n",
    "        max_drawdown = 0  # No data, set drawdown to 0\n",
    "\n",
    "\n",
    "    # Plot the results\n",
    "    backtest.plot_results(cerebro)\n",
    "\n",
    "    return {\n",
    "        'cumulative_return': cumulative_return,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'final_value': final_value\n",
    "    }\n",
    "\n",
    "def run_ssl_rsi_atr_backtest(ticker, ssl_period=10, rsi_period=14, rsi_buy=30, rsi_sell=70, atr_period=14, atr_multiplier=2.0):\n",
    "    \"\"\"\n",
    "    Run a backtest on the specified ticker using both SSL and RSI strategies.\n",
    "    \n",
    "    Parameters:\n",
    "        ticker (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "        ssl_period (int): The period for the SSL Semaphore Signal (moving averages).\n",
    "        rsi_period (int): The period for calculating the RSI indicator.\n",
    "        rsi_buy (int): The RSI level below which to buy.\n",
    "        rsi_sell (int): The RSI level above which to sell.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing performance metrics (cumulative return, Sharpe ratio, final value).\n",
    "    \"\"\"\n",
    "    # Fetch historical data\n",
    "    data = fetch_data(ticker, '2010-01-01', '2024-09-09')\n",
    "\n",
    "    # Define the combined SSL and RSI strategy with the chosen parameters\n",
    "    strategy = SSL_RSI_ATR_Strategy\n",
    "\n",
    "    # Create the backtest with the chosen strategy and data\n",
    "    backtest = Backtest(strategy, data, cash=50000, commission=0.001)\n",
    "\n",
    "    # Run the backtest\n",
    "    cerebro, results = backtest.run_backtest(ssl_period=ssl_period, \n",
    "                                             rsi_period=rsi_period, \n",
    "                                             rsi_buy=rsi_buy, \n",
    "                                             rsi_sell=rsi_sell,\n",
    "                                             atr_period=atr_period,\n",
    "                                             atr_multiplier=atr_multiplier)\n",
    "\n",
    "    # Get the initial and final portfolio values directly from Backtrader\n",
    "    initial_value = backtest.cash  # Initial value is the cash we started with\n",
    "    final_value = cerebro.broker.getvalue()  # Final portfolio value after the backtest\n",
    "\n",
    "    # Calculate cumulative return\n",
    "    cumulative_return = (final_value - initial_value) / initial_value * 100  # In percentage\n",
    "\n",
    "    # Calculate Sharpe Ratio (you can refine this calculation)\n",
    "    daily_returns = data['Close'].pct_change().dropna()\n",
    "    sharpe_ratio = (daily_returns.mean() / daily_returns.std()) * (252 ** 0.5)  # Annualized Sharpe Ratio\n",
    "\n",
    "    # Maximum Drawdown\n",
    "    # Extract portfolio values for maximum drawdown calculation\n",
    "    portfolio_values = [x.broker.getvalue() for x in results]\n",
    "\n",
    "    # Compute maximum drawdown\n",
    "    if portfolio_values:  # Ensure portfolio_values is not empty\n",
    "        max_drawdown = (1 - min(portfolio_values) / max(portfolio_values)) * 100  # In percentage\n",
    "    else:\n",
    "        max_drawdown = 0  # No data, set drawdown to 0\n",
    "\n",
    "    # Plot the results\n",
    "    backtest.plot_results(cerebro)\n",
    "\n",
    "    return {\n",
    "        'cumulative_return': cumulative_return,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'final_value': final_value\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429a571-1162-40eb-846e-c81f53a4daf7",
   "metadata": {},
   "source": [
    "<h2>Correlation between the SSL and RSI Indicators</h2>\n",
    "\n",
    "<p>Experience conflicting signals between SSL and RSI. They appear to be uncorrelated. RSI is signaling a buy while the SSL is signaling a sell. RSI is oscillatory measuring momentum and SSL is trend following. Contradiction occurs in volatile markets.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c22981-db35-4448-9f55-afbf82c9c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "corr_df = fetch_data('NVDA', '2010-01-01', '2024-09-09')\n",
    "corr_df.dropna(inplace=True)\n",
    "\n",
    "corr_df['RSI'] = talib.RSI(corr_df['Close'], timeperiod=14)\n",
    "corr_df['SMA_High'] = talib.SMA(corr_df['High'], timeperiod=21)\n",
    "corr_df['SMA_Low'] = talib.SMA(corr_df['Low'], timeperiod=21)\n",
    "\n",
    "correlation_matrix = corr_df[['RSI', 'SMA_High', 'SMA_Low']].corr()\n",
    "print(\"Correlation Matrix\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd16e69-c67c-42ca-95b4-fbfda74952e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage to run the backtest and output results:\n",
    "results = run_ssl_rsi_atr_backtest('NVDA', ssl_period=41, rsi_period=13, rsi_buy=41, rsi_sell=74, atr_period=14, atr_multiplier=2.0)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Cumulative Return: {results['cumulative_return']:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {results['sharpe_ratio']:.2f}\")\n",
    "print(f\"Max Drawdown: {results['max_drawdown']:.2f}%\")\n",
    "print(f\"Final Portfolio Value: ${results['final_value']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001579e3-c312-4118-9d4b-dc0366d6a230",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Grid Search</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e8806-7f0f-4a31-a89e-b0316203e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI levels as hyperparameters that need to be optimized, similar to how hyperparameters are tuned. \n",
    "# Grid Search \n",
    "\n",
    "import itertools\n",
    "\n",
    "# Define the range of RSI buy and sell levels to test\n",
    "rsi_buy_levels = range(10, 50, 5)  # Buy if RSI < level (e.g., 10, 15, 20, ..., 45)\n",
    "rsi_sell_levels = range(50, 90, 5)  # Sell if RSI > level (e.g., 50, 55, 60, ..., 85)\n",
    "\n",
    "results = [] \n",
    "\n",
    "# Iterate over all combinations of RSI levels\n",
    "for buy_level, sell_level in itertools.product(rsi_buy_levels, rsi_sell_levels):\n",
    "    print(f\"Testing Buy RSI: {buy_level}, Sell RSI: {sell_level}\")\n",
    "    performance = run_rsi_backtest('NVDA', rsi_buy=buy_level, rsi_sell=sell_level)\n",
    "\n",
    "    # Store the performance metrics\n",
    "    results.append({'buy_level': buy_level, \n",
    "                    'sell_level': sell_level, \n",
    "                    'performance': performance,\n",
    "                    'cumulative_return': performance['cumulative_return'],\n",
    "                    'sharpe_ratio': performance['sharpe_ratio'],\n",
    "                    'final_value': performance['final_value']})\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d9ed2-9c91-4c12-99fe-2dc760f848a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize and Tune as needed\n",
    "\n",
    "# Sort the results by Sharpe Ratio or Cumulative Return\n",
    "# For Sharpe Ratio:\n",
    "best_result_by_sharpe = max(results, key=lambda x: x['sharpe_ratio'])\n",
    "\n",
    "# For Cumulative Return:\n",
    "best_result_by_return = max(results, key=lambda x: x['cumulative_return'])\n",
    "\n",
    "# Print the optimal RSI levels and their performance (by Sharpe Ratio)\n",
    "print(f\"Optimal Buy Level (Sharpe): {best_result_by_sharpe['buy_level']}, Optimal Sell Level (Sharpe): {best_result_by_sharpe['sell_level']}\")\n",
    "print(f\"Sharpe Ratio: {best_result_by_sharpe['sharpe_ratio']}\")\n",
    "print(f\"Cumulative Return: {best_result_by_sharpe['cumulative_return']}\")\n",
    "print(f\"Final Portfolio Value: {best_result_by_sharpe['final_value']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70901693-2c04-4165-a8c7-d616aa719638",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Bayseian Optimization RSI</h2>\n",
    "<p> A method that balances exploration and exploitation. It uses past performance to build a model (usually a Gaussian Process) and directs it search toward more promising areas of the search space. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e442f-0d35-4b8a-8bd2-92de3b936b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer\n",
    "import numpy as np\n",
    "\n",
    "# Define the objective function for Bayesian optimization\n",
    "def objective(params):\n",
    "    rsi_buy, rsi_sell, rsi_period = params\n",
    "    \n",
    "    # Run backtest and get the performance metrics\n",
    "    performance = run_rsi_backtest('NVDA', rsi_buy=rsi_buy, rsi_sell=rsi_sell, rsi_period=rsi_period)\n",
    "    \n",
    "    # We want to maximize Sharpe ratio or cumulative return, but `gp_minimize` minimizes by default,\n",
    "    # so we return the negative of the metric we want to maximize.\n",
    "    return -performance['sharpe_ratio']  # or -performance['cumulative_return']\n",
    "\n",
    "# Define the search space for RSI buy and sell levels\n",
    "search_space = [\n",
    "    Integer(10, 45, name='rsi_buy'),  # Search between RSI 10 to 45 for buying\n",
    "    Integer(50, 85, name='rsi_sell'),  # Search between RSI 50 to 85 for selling\n",
    "    Integer(7, 30, name='rsi_period')  # Search for the best RSI period between 7 and 30\n",
    "]\n",
    "\n",
    "# Early stopping parameters\n",
    "n_calls = 40  # Maximum number of calls\n",
    "convergence_threshold = 0.01  # Minimum improvement required to continue optimization\n",
    "early_stop_iteration = 3  # Number of iterations to check for convergence\n",
    "\n",
    "# Run Bayesian optimization\n",
    "result = gp_minimize(objective, search_space, n_calls=n_calls, random_state=42)\n",
    "\n",
    "# Check for early stopping based on improvement\n",
    "stopped_early = False\n",
    "for i in range(early_stop_iteration, n_calls):\n",
    "    current_best = -result.func_vals[i]  # Convert back to positive Sharpe ratio\n",
    "    previous_best = -result.func_vals[i - early_stop_iteration]\n",
    "\n",
    "    improvement = abs(current_best - previous_best)\n",
    "    if improvement < convergence_threshold:\n",
    "        print(f\"Stopping early at iteration {i} due to convergence.\")\n",
    "        stopped_early = True\n",
    "        break\n",
    "        \n",
    "# Get the optimal RSI levels\n",
    "optimal_rsi_buy = result.x[0]\n",
    "optimal_rsi_sell = result.x[1]\n",
    "optimal_rsi_period = result.x[2]\n",
    "\n",
    "print(f\"Optimal RSI Buy Level: {optimal_rsi_buy}\")\n",
    "print(f\"Optimal RSI Sell Level: {optimal_rsi_sell}\")\n",
    "print(f\"Optimal RSI Period: {optimal_rsi_period}\")\n",
    "\n",
    "# Get the optimal Sharpe ratio or cumulative return\n",
    "best_sharpe_ratio = -result.fun  # Since we minimized the negative Sharpe ratio, revert it\n",
    "print(f\"Optimal Sharpe Ratio: {best_sharpe_ratio}\")\n",
    "\n",
    "if stopped_early:\n",
    "    print(f\"Bayesian optimization stopped early at iteration {i} due to lack of improvement.\")\n",
    "else:\n",
    "    print(f\"Bayesian optimization completed all {n_calls} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a74e066-90b8-45da-b843-7ef673b78516",
   "metadata": {},
   "source": [
    "<h2>Bayesian Optimization SSL period & RSI threshholds / Periods</h2>\n",
    "Optimizing the indicators together is best practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5a817f-2abd-418f-8b63-7ca233c9137a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer\n",
    "\n",
    "# Define the objective function for optimizing both SSL and RSI parameters\n",
    "def objective(params):\n",
    "    ssl_period, rsi_period, rsi_buy, rsi_sell = params\n",
    "    \n",
    "    # Run backtest and get the performance metrics\n",
    "    performance = run_ssl_rsi_backtest('NVDA', ssl_period=ssl_period, rsi_period=rsi_period, rsi_buy=rsi_buy, rsi_sell=rsi_sell)\n",
    "    \n",
    "    # We want to maximize Sharpe ratio, but `gp_minimize` minimizes by default,\n",
    "    # so we return the negative of the Sharpe ratio to maximize it.\n",
    "    return -performance['sharpe_ratio']\n",
    "\n",
    "# Define the search space for SSL and RSI parameters\n",
    "search_space = [\n",
    "    Integer(5, 50, name='ssl_period'),   # SSL period\n",
    "    Integer(5, 50, name='rsi_period'),   # RSI period\n",
    "    Integer(10, 50, name='rsi_buy'),     # RSI Buy threshold\n",
    "    Integer(50, 90, name='rsi_sell')     # RSI Sell threshold\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "result = gp_minimize(objective, search_space, n_calls=30, random_state=42)\n",
    "\n",
    "# Get the optimal parameters\n",
    "optimal_ssl_period = result.x[0]\n",
    "optimal_rsi_period = result.x[1]\n",
    "optimal_rsi_buy = result.x[2]\n",
    "optimal_rsi_sell = result.x[3]\n",
    "\n",
    "print(f\"Optimal SSL Period: {optimal_ssl_period}\")\n",
    "print(f\"Optimal RSI Period: {optimal_rsi_period}\")\n",
    "print(f\"Optimal RSI Buy Level: {optimal_rsi_buy}\")\n",
    "print(f\"Optimal RSI Sell Level: {optimal_rsi_sell}\")\n",
    "\n",
    "# Get the best Sharpe ratio\n",
    "best_sharpe_ratio = -result.fun\n",
    "print(f\"Best Sharpe Ratio: {best_sharpe_ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4bda41-727c-4763-85b4-9bd5b927f93d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Implement the SSL Semaphore Indicator for generating buy / sell signals\n",
    "import talib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def calculate_moving_averages(df, high_col='high', low_col='low', period=10):\n",
    "    \"\"\"\n",
    "    Calculate the moving averages for the high and low prices.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing stock data\n",
    "    high_col (str): Column name for high prices\n",
    "    low_col (str): Column name for low prices\n",
    "    period (int): Period for calculating moving averages\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with 'sma_high' and 'sma_low' columns added\n",
    "    \"\"\"\n",
    "    df['sma_high'] = talib.SMA(df[high_col], timeperiod=period)\n",
    "    df['sma_low'] = talib.SMA(df[low_col], timeperiod=period)\n",
    "    return df\n",
    "\n",
    "def generate_ssl_signals(df, close_col='close', sma_high_col='sma_high', sma_low_col='sma_low'):\n",
    "    \"\"\"\n",
    "    Generate buy and sell signals based on crossovers between the closing price\n",
    "    and the moving averages applied to the high and low prices.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing stock data\n",
    "    close_col (str): Column name for close prices\n",
    "    sma_high_col (str): Column name for the high-based moving average\n",
    "    sma_low_col (str): Column name for the low-based moving average\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with 'buy_signal' and 'sell_signal' columns added\n",
    "    \"\"\"\n",
    "    df.loc[:,'buy_signal'] = np.where(df[close_col] > df[sma_high_col], 1, 0)\n",
    "    df.loc[:,'sell_signal'] = np.where(df[close_col] < df[sma_low_col], -1, 0)\n",
    "    return df\n",
    "\n",
    "def plot_ssl_signals(df, close_col='close', sma_high_col='sma_high', sma_low_col='sma_low', buy_signal_col='buy_signal', sell_signal_col='sell_signal', start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Plot the SSL semaphore signals along with the stock price and moving averages.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing stock data\n",
    "    close_col (str): Column name for close prices\n",
    "    sma_high_col (str): Column name for the high-based moving average\n",
    "    sma_low_col (str): Column name for the low-based moving average\n",
    "    buy_signal_col (str): Column name for buy signals\n",
    "    sell_signal_col (str): Column name for sell signals\n",
    "    start_date (str or datetime): Start date for zooming into a particular time range\n",
    "    end_date (str or datetime): End date for zooming into a particular time range\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Optionally filter the dataframe for the given date range\n",
    "    if start_date and end_date:\n",
    "        df = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "    \n",
    "    plt.plot(df[close_col], label='Close Price', color='black')\n",
    "    plt.plot(df[sma_high_col], label='SMA High', color='green')\n",
    "    plt.plot(df[sma_low_col], label='SMA Low', color='red')\n",
    "    \n",
    "    # Plot buy signals only where buy_signal == 1\n",
    "    plt.scatter(df.index[df[buy_signal_col] == 1], df[close_col][df[buy_signal_col] == 1], \n",
    "                label='Buy Signal', marker='^', color='blue', alpha=1, s=100)\n",
    "    \n",
    "    # Plot sell signals only where sell_signal == -1\n",
    "    plt.scatter(df.index[df[sell_signal_col] == -1], df[close_col][df[sell_signal_col] == -1], \n",
    "                label='Sell Signal', marker='v', color='red', alpha=1, s=100)\n",
    "\n",
    "    plt.title('SSL Semaphore Signal Level')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97636d0-2fbf-4a1a-b7f1-b64ee0263029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_moving_averages(data)\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "df_cleaned\n",
    "\n",
    "df_cleaned = generate_ssl_signals(df_cleaned)\n",
    "\n",
    "plot_ssl_signals(df_cleaned, start_date='2023-10-01', end_date='2024-02-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2808631-df4f-4102-8675-dfe4f3d70c42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Back Testing using Back Trader Object Oriented \n",
    "import backtrader as bt\n",
    "import backtrader.plot as bplot\n",
    "import backtrader.analyzers as btanalyzers\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the SSL Strategy\n",
    "class SSLStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        # Define the indicators we want to use\n",
    "        self.sma_high = bt.indicators.SimpleMovingAverage(self.data.high, period=10)\n",
    "        self.sma_low = bt.indicators.SimpleMovingAverage(self.data.low, period=10)\n",
    "        self.rsi = bt.indicators.RelativeStrengthIndex(self.data.close, period=14)\n",
    "        self.macd = bt.indicators.MACD(self.data.close)\n",
    "\n",
    "    # The next() method is called for every bar (daily, hourly, etc.)\n",
    "    def next(self):\n",
    "        # Buy condition: Close price above SMA high, RSI < X, and MACD > Signal\n",
    "        if self.data.close > self.sma_high and self.rsi < 10 and self.macd.macd > self.macd.signal:\n",
    "            self.buy()\n",
    "\n",
    "        # Sell condition: Close price below SMA low, RSI > X, and MACD < Signal\n",
    "        elif self.data.close < self.sma_low and self.rsi > 50 and self.macd.macd < self.macd.signal:\n",
    "            self.sell()\n",
    "\n",
    "# Initialize Backtrader\n",
    "cerebro = bt.Cerebro()\n",
    "\n",
    "# Add the SSL Strategy to Backtrader\n",
    "cerebro.addstrategy(SSLStrategy)\n",
    "\n",
    "# Convert the pandas DataFrame into Backtrader Data Feed\n",
    "data_feed = bt.feeds.PandasData(dataname=df_cleaned)\n",
    "\n",
    "# Add the data feed to Backtrader\n",
    "cerebro.adddata(data_feed)\n",
    "\n",
    "# Add analyzers to Backtrader\n",
    "cerebro.addanalyzer(btanalyzers.TradeAnalyzer, _name='trade_analyzer')\n",
    "cerebro.addanalyzer(btanalyzers.Returns, _name='returns')\n",
    "\n",
    "# Run the backtest\n",
    "results = cerebro.run()\n",
    "\n",
    "# Accessing the results of the analyzers\n",
    "trade_analyzer = results[0].analyzers.trade_analyzer.get_analysis()\n",
    "returns_analyzer = results[0].analyzers.returns.get_analysis()\n",
    "\n",
    "# Print the trade analysis\n",
    "print(\"Trade Analysis:\")\n",
    "for key, value in trade_analyzer.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Print the returns analysis\n",
    "print(\"\\nReturns Analysis:\")\n",
    "for key, value in returns_analyzer.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 9, 1)\n",
    "\n",
    "# Generate the plot with Backtrader\n",
    "cerebro.plot(iplot=False, style='candlestick', volume=True, barup='green', bardown='red',start=start_date, end=end_date)  # This returns a list of figures\n",
    "\n",
    "# Print trade statistics\n",
    "print(f\"Total Trades: {trade_analyzer.total.closed}\")\n",
    "print(f\"Winning Trades: {trade_analyzer.won.total}\")\n",
    "print(f\"Losing Trades: {trade_analyzer.lost.total}\")\n",
    "print(f\"Total PnL: {trade_analyzer.pnl.net.total}\")\n",
    "print(f\"Strike Rate: {trade_analyzer.won.total / trade_analyzer.total.closed * 100:.2f}%\")\n",
    "\n",
    "# Print returns statistics\n",
    "print(f\"Total Return: {returns_analyzer.rnorm100}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4988e-2b6f-4de8-91ec-65b02bf828c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Volume Indicator (On-Balance Volume - OBV)\n",
    "df_cleaned.loc[:, 'obv'] = talib.OBV(df_cleaned['close'], df_cleaned['volume'])\n",
    "\n",
    "# Momentum Indicators (RSI and MACD)\n",
    "df_cleaned.loc[:, 'rsi'] = talib.RSI(df_cleaned['close'], timeperiod=21)\n",
    "\n",
    "# Assign MACD, signal, and histogram\n",
    "df_cleaned.loc[:, 'macd'], df_cleaned.loc[:, 'macdsignal'], df_cleaned.loc[:, 'macdhist'] = talib.MACD(df_cleaned['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e12e30-91bc-4816-a209-ee9b2473ee86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "# I attempt to optimize features below\n",
    "df_cleaned.loc[:, 'rsi_buy'] = (df_cleaned['rsi'] < 30).astype(int)  # Buy if RSI < 30\n",
    "df_cleaned.loc[:, 'rsi_sell'] = (df_cleaned['rsi'] > 70).astype(int)  # Sell if RSI > 70\n",
    "\n",
    "df_cleaned = df_cleaned.drop(columns=['buy_signal', 'sell_signal'])\n",
    "\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2966b-7ed1-411e-876f-b1bfbf08db9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Strategy Implementation\n",
    "# Signals SSL, Volume, and Momentum\n",
    "# Define rules for buying, selling, and holding\n",
    "# RSI, MACD\n",
    "\n",
    "def generate_trading_signals(df):\n",
    "    \n",
    "    # Conditions for buying\n",
    "    df.loc[:, 'buy'] = np.where((df['rsi'] < 10) & (df['macd'] > df['macdsignal']), 1, 0)\n",
    "    \n",
    "    # Conditions for selling\n",
    "    df.loc[:, 'sell'] = np.where((df['rsi'] > 50) & (df['macd'] < df['macdsignal']), -1, 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_macd_signals(df):\n",
    "    # Conditions for buying\n",
    "    df.loc[:, 'buy'] = np.where((df['macd'] > df['macdsignal']), 1, 0)\n",
    "    \n",
    "    # Conditions for selling\n",
    "    df.loc[:, 'sell'] = np.where((df['macd'] < df['macdsignal']), -1, 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_rsi_signals(df):\n",
    "    # Conditions for buying\n",
    "    df.loc[:, 'buy'] = np.where((df['rsi'] < 30), 1, 0)\n",
    "    \n",
    "    # Conditions for selling\n",
    "    df.loc[:, 'sell'] = np.where((df['rsi'] > 50), -1, 0)\n",
    "\n",
    "    return df\n",
    "        \n",
    "\n",
    "\n",
    "df_cleaned = generate_trading_signals(df_cleaned)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b99ace-2edd-4866-8615-c4c6779684ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_macd_rsi(df, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Plot MACD and RSI with buy and sell signals, and allow zooming by date range.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing MACD, MACD Signal, buy and sell signals, RSI, etc.\n",
    "    start_date (str or pd.Timestamp): Start date for the plot (optional)\n",
    "    end_date (str or pd.Timestamp): End date for the plot (optional)\n",
    "    \"\"\"\n",
    "\n",
    "     # Optionally filter the DataFrame for the given date range\n",
    "    if start_date and end_date:\n",
    "        df = df[(df.index >= pd.to_datetime(start_date)) & (df.index <= pd.to_datetime(end_date))]\n",
    "\n",
    "    # Plotting MACD and Signal line with crossovers\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Create subplots: 2 rows, 1 column\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "    \n",
    "    # Plot MACD and Signal line on the first subplot (ax1)\n",
    "    ax1.plot(df.index, df['macd'], label='MACD', color='blue')\n",
    "    ax1.plot(df.index, df['macdsignal'], label='Signal Line', color='orange')\n",
    "\n",
    "    # Highlight buy and sell signals on MACD plot\n",
    "    ax1.scatter(df.index[df['buy'] == 1], df['macd'][df['buy'] == 1], label='Buy Signal', marker='^', color='green', s=100)\n",
    "    ax1.scatter(df.index[df['sell'] == -1], df['macd'][df['sell'] == -1], label='Sell Signal', marker='v', color='red', s=100)\n",
    "\n",
    "    # Add labels, legend, and title for MACD plot\n",
    "    ax1.set_title('MACD Crossovers with Buy and Sell Signals')\n",
    "    ax1.axhline(0, color='black', linestyle='--', linewidth=1)  # Horizontal line at MACD 0\n",
    "    ax1.set_ylabel('MACD')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Plot RSI on the second subplot (ax2)\n",
    "    ax2.plot(df.index, df['rsi'], label='RSI', color='purple')\n",
    "    ax2.axhline(10, color='green', linestyle='--')  # RSI oversold line\n",
    "    ax2.axhline(50, color='red', linestyle='--')    # RSI overbought line\n",
    "\n",
    "    # Add labels, legend, and title for RSI plot\n",
    "    ax2.set_title('RSI')\n",
    "    ax2.set_ylabel('RSI')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Tight layout for better spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "plot_macd_rsi(df_cleaned, start_date='2023-01-01', end_date='2024-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb233971-9079-46d1-a5e4-2847e7d69914",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Export Trade To CSV or Data Frame for futher analysis \n",
    "\n",
    "# After running the backtest, you can extract trade data from TradeAnalyzer\n",
    "trade_list = []\n",
    "\n",
    "for trade in results[0].analyzers.trade_analyzer.get_analysis().closed:\n",
    "    trade_data = {\n",
    "        'Date': trade.dtclose,\n",
    "        'Entry Price': trade.pricein,\n",
    "        'Exit Price': trade.priceout,\n",
    "        'Profit/Loss': trade.pnl,\n",
    "        'Commission': trade.commission,\n",
    "        'Size': trade.size\n",
    "    }\n",
    "    trade_list.append(trade_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_trades = pd.DataFrame(trade_list)\n",
    "df_trades.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f11a5a-c8e8-4de0-9d2d-98a415685ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_conda",
   "language": "python",
   "name": "python3_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
